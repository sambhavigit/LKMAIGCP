

Vertex AI Codey API
This notebook shows a few examples of using Codey via the latest Vertex AI SDK.

What are LLMs Large language models (LLMs) are deep learning models trained on massive datasets of text. LLMs can translate language, summarize text, generate creative writing, generate code, power chatbots and virtual assistants, and complement search engines and recommendation systems. Creating an LLM requires massive amounts of data, significant compute resources, and specialized skills. Because LLMs require a big investment to create, they target broad rather than specific use cases. On Vertex AI, you can customize a foundation model for more specific tasks or knowledge domains by using prompt design and model tuning. The Vertex AI PaLM API enables you to test, customize, and deploy instances of Google’s large language models (LLM) so that you can leverage the capabilities of PaLM in your applications. PaLM 2 is Google's next generation Large Language Model (LLM) that builds on Google's legacy of breakthrough research in machine learning and responsible AI. PaLM 2 excels at tasks like advanced reasoning, translation, and code generation because of how it was built. Generative AI Studio and the Vertex AI PaLM API is powered by PaLM 2. Objectives:

✅ Introduce Vertex PaLM API Text

✅ Introduce Codey PaLM API components

✅ Codey generated code samples

Setup
Install the latest Vertex AI SDK for python

!pip install google-cloud-aiplatform --upgrade --user
⚠️ Do not forget to click the "RESTART RUNTIME" button above.
First let's set the GCP Project ID and use this to initialize the Vertex AI SDK. Please enter the project id and location.

from google.colab import auth as google_auth
google_auth.authenticate_user()
PROJECT_ID = "<Enter your project id>" #@param {type:"string"}
LOCATION = "us-central1" #@param {type:"string"}
Import the required libararies and initialize the sdk using project and location
from google.cloud import aiplatform
from vertexai.language_models._language_models import TextGenerationModel, ChatModel, CodeChatModel, CodeGenerationModel

aiplatform.init(project=PROJECT_ID, location=LOCATION)
print(f"Vertex AI SDK version: {aiplatform.__version__} initialized!")

from vertexai.language_models._language_models import CodeGenerationModel
import IPython.display as display
Vertex AI SDK version: 1.30.1 initialized!
Let's use codey to generate code!
⚠️ You are using the model - code-bison@001.
PROMPT = "write a python function to find a leap year" #@param {type:"string"}
from vertexai.language_models._language_models import CodeGenerationModel
import IPython.display as display

codegen = CodeGenerationModel.from_pretrained("code-bison@001")

result = codegen.predict(
    PROMPT,
    # Optional:
    max_output_tokens=528,
    temperature=0.65,
    #top_p=1,
    #top_k=5,
)

display.Markdown(result.text)
def is_leap_year(year):
  """
  Determines whether a year is a leap year.

  Args:
    year: The year to check.

  Returns:
    True if the year is a leap year, False otherwise.
  """

  # A year is a leap year if it is divisible by 4, unless it is divisible by 100
  # unless it is also divisible by 400.

  if year % 4 == 0:
    if year % 100 == 0:
      return year % 400 == 0
    else:
      return True
  else:
    return False
Let's use codey to write a unit test for a function
PROMPT = """Write a unit test for this function
def is_leap_year(year):
  if year % 4 == 0:
    if year % 100 == 0:
      if year % 400 == 0:
        return True
      else:
        return False
    else:
      return True
  else:
    return False

    """

response = codegen.predict(
    PROMPT,
    # Optional:
    max_output_tokens=654,
    temperature=0.65,
    #top_p=1,
    #top_k=5,
)

print(response)
```python
def test_is_leap_year():
  """Test for the function is_leap_year."""

  # Check that the function returns True for years that are divisible by 400.
  assert is_leap_year(400) == True

  # Check that the function returns True for years that are divisible by 100 but not by 400.
  assert is_leap_year(100) == False

  # Check that the function returns True for years that are divisible by 4 but not by 100.
  assert is_leap_year(4) == True

  # Check that the function returns False for years that are not divisible by 4.
  assert is_leap_year(3) == False

```
Another Example
PROMPT = """Write an http server in Go that takes a JSON message as a POST, extracts the name, and returns it, prepending "hello ".
Make sure the HTTP handler is in a separate method.
Here is an example JSON:

{"name":"squirrel"}

"""

response = codegen.predict(
    PROMPT,
    # Optional:
    max_output_tokens=654,
    temperature=0.65,
    #top_p=1,
    #top_k=5,
)


display.Markdown(response.text)
package main

import (
    "encoding/json"
    "fmt"
    "log"
    "net/http"
)

// HandlerFunc defines the handler function type.
type HandlerFunc func(http.ResponseWriter, *http.Request)

// ServeHTTP implements the http.Handler interface.
func (h HandlerFunc) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    h(w, r)
}

// HelloHandler is the HTTP handler that greets the user.
func HelloHandler(w http.ResponseWriter, r *http.Request) {
    // Decode the JSON message.
    var name struct {
        Name string `json:"name"`
    }
    if err := json.NewDecoder(r.Body).Decode(&name); err != nil {
        log.Fatal(err)
    }

    // Prepend "hello " to the name and return it.
    fmt.Fprintf(w, "hello %s\n", name.Name)
}

func main() {
    // Create a new HTTP server.
    http.HandleFunc("/hello", HelloHandler)
    server := http.Server{Addr: ":8080"}

    // Start the HTTP server.
    if err := server.ListenAndServe(); err != nil {
        log.Fatal(err)
    }
}
Let's try chat codey to generate code!
⚠️ You are using the model - codechat-bison@001.
import vertexai
from vertexai.preview.language_models import CodeChatModel

vertexai.init(project=PROJECT_ID, location="us-central1")
chat_model = CodeChatModel.from_pretrained("codechat-bison@001")
parameters = {
    "temperature": 0.2,
    "max_output_tokens": 1024
}


chat = chat_model.start_chat()
response = chat.send_message("""Hi, how are you?""", **parameters)
print(f"Response from Model: {response.text}")
Response from Model: I am doing well, thank you for asking! I am excited to be learning more about natural language processing and how to use it to help people.
response = chat.send_message("""I am doing good. What Can I help you with in the coding world?""", **parameters)
print(f"Response from Model: {response.text}")
Response from Model: There are many things you can help me with in the coding world! For example, you can help me learn new programming languages, debug my code, and give me feedback on my projects.
response = chat.send_message("""Please help write a function to calculate the min of two numbers""", **parameters)
print(f"Response from Model: {response.text}")
Response from Model: Sure, here is a function to calculate the minimum of two numbers:

```
def min(a, b):
  """
  Calculates the minimum of two numbers.

  Args:
    a: The first number.
    b: The second number.

  Returns:
    The smaller of the two numbers.
  """

  if a < b:
    return a
  else:
    return b
```

This function takes two numbers as input and returns the smaller of the two numbers.
response = chat.send_message("""Please change the previous function variables from a to first_num and b to second_num""", **parameters)
print(f"Response from Model: {response.text}")
Response from Model: Sure, here is the function with the variable names changed:

```
def min(first_num, second_num):
  """
  Calculates the minimum of two numbers.

  Args:
    first_num: The first number.
    second_num: The second number.

  Returns:
    The smaller of the two numbers.
  """

  if first_num < second_num:
    return first_num
  else:
    return second_num
```
# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
